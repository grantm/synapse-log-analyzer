#!/usr/bin/perl
##############################################################################
#
# A script for examining Synapse server logs.
#
# See --help for more info.
#
# To install dependencies, on Debian/Ubuntu:
#
#  apt-install libjson-maybexs-perl
#
# Docs for log format at:
# https://matrix-org.github.io/synapse/latest/usage/administration/request_log.html
#

use 5.020;
use strict;
use warnings;
use autodie;
use utf8;
use open qw( :encoding(UTF-8) :std );

use File::Spec::Functions qw(splitpath catfile);
use Pod::Usage            qw(pod2usage);
use Getopt::Long          qw(GetOptionsFromArray);
use POSIX                 qw();
use JSON::MaybeXS         qw(decode_json JSON);
use Data::Dumper          qw(Dumper);



my $buffer_expiry = 600;    # discard buffered lines after 10min

my $initial_fields = qr{
    \A
    (?<ts_date>[0-9]{4}-[0-9]{2}-[0-9]{2})[ ]
    (?<ts_time>[0-9]{2}:[0-9]{2}:[0-9]{2}),
    (?<ts_ms>\d+)[ ]-[ ]
    (?<logger>\S+)[ ]-[ ]
    (?<code_line>\d+)[ ]-[ ]
    (?<log_level>\w+)[ ]-[ ]
    (?<request_id>\S+)[ ]-[ ]
}x;

my $request_line = qr{
    $initial_fields
    (?<client_ip>\S+)[ ]-[ ]
    (?<server_port>\S+)[ ]-[ ]
    \{(?<user>\S*)\}[ ]
    Processed[ ]request:[ ]
    (?<time_elapsed>[0-9.]+)sec/
    -?(?<time_send>[0-9.]+)sec[ ][(]
    (?<time_user>[0-9.]+)sec,[ ]
    (?<time_sys>[0-9.]+)sec[)][ ][(]
    (?<time_db_pool>[0-9.]+)sec/
    (?<time_db_queries>[0-9.]+)sec/
    (?<count_db_txn>[0-9]+)[)][ ]
    (?<resp_bytes>\d+)B[ ]
    (?<resp_code>\d+)(?<resp_abandoned>!?)[ ]
    "(?<req_method>\w+)[ ](?<req_path>[^?\s]+)(?<req_query>(?:[?]\S+)?)[ ][^"]+"[ ]
    "(?<user_agent>[^"]+)"[ ]
    \[(?<count_db_evts>[0-9]+)[ ]dbevts\]
}xn;

my $non_request_line = qr{
    $initial_fields
    (?<log_message>\S.*)$
}xn;

my @known_fields = qw(
    log_path
    log_file
    timestamp
    ts_date
    ts_time
    logger
    code_line
    log_level
    request_id
    client_ip
    server_port
    user
    user_local
    user_domain
    time_elapsed
    time_send
    time_user
    time_sys
    time_db_pool
    time_db_queries
    count_db_txn
    resp_bytes
    resp_code
    resp_abandoned
    req_method
    req_path
    req_query
    user_agent
    count_db_evts
    extra_lines
);
my %field_is_known = map { $_ => 1 } @known_fields;


my $conf_file = catfile(home_dir(), '.synapse-log-analyzer.json');
my %settings = load_settings();

my @expanded_args = apply_option_bundles(@ARGV);

my %opt = (
    filter    => [],
);

if(!GetOptionsFromArray(
    \@expanded_args,
    \%opt,
    'output|o=s',
    'json',
    'fields=s',
    'filter|f=s',
    'list_fields|list-fields',
    'regex=s',
    'tally',
    'help|?',
)) {
    pod2usage(-exitval => 1,  -verbose => 0);
}


if($opt{help}) {
    pod2usage(-exitstatus => 0, -verbose => 2);
}
elsif($opt{list_fields}) {
    list_known_fields();
}
else {
    if($opt{output} && $opt{json}) {
        pod2usage(
            -exitval => 1,  -verbose => 0,
            -message => "Please use either --output or --json, not both"
        );
    }
    my $regex     = $opt{regex} ? qr{$opt{regex}} : '';
    my $filter    = make_filter($opt{filter});
    my $formatter = $opt{json}
        ? json_formatter($opt{fields})
        : make_formatter($opt{output}, $opt{fields});
    my @log_files = log_paths(@expanded_args);
    analyse_logs(
        regex         => $regex,
        filter        => $filter,
        formatter     => $formatter,
        tally_output  => $opt{tally},
        log_files     => \@log_files,
    );
}
exit 0;


sub load_settings {
    my %settings;

    if(-e $conf_file) {
        local($/) = undef; # slurp file mode
        open(my $fh, '<:raw', $conf_file);
        my $json = <$fh>;
        my $obj = decode_json($json);
        if(ref($obj) ne "HASH") {
            die "Expected $conf_file to contain a JSON object { ... }\n";
        }
        %settings = %$obj;
    }
    return %settings;
}


sub home_dir {
    return (getpwuid($<))[7];
}


sub apply_option_bundles {
    my $bundles = $settings{bundles} // {};
    if(ref($bundles) ne "HASH") {
        die qq{Expected "bundles" in $conf_file to contain a JSON object { ... }\n};
    }
    my @out;
    while(@_) {
        my $arg = shift(@_);
        if($arg eq '-b' or $arg eq '--bundle') {
            my $name = shift(@_) // die "$arg needs a bundle name\n";
            my $val = $bundles->{$name}
                // die qq{Unknown bunlde name: "$name"\n};
            if(ref($val) ne 'ARRAY') {
                die qq{Expected value for bundle "$name" to be a JSON array [ ... ]\n};
            }
            push @out, @$val;
        }
        else {
            push @out, $arg;
        }
    }
    return @out;
}


sub list_known_fields {
    say "Known fields:";
    say " - $_" foreach @known_fields;
}


sub make_filter {
    my($filter_specs) = @_;

    if(!$filter_specs or !@$filter_specs) {
        return;
    }

    # Multiple filters are implicitly and'd together
    my @subs = grep { $_ } map { compile_filter($_) } @$filter_specs;
    return sub {
        my $rec = shift;
        foreach my $sub (@subs) {
            return 0 unless $sub->($rec);
        }
        return 1;
    }
}


sub compile_filter {
    my($spec) = @_;

    if(
        $spec =~ m{
            \A\s*
            (?<field_name>\w+)\s*
            (?<comparator>(?:!=|=|!~|~))\s*
            (?<value>.*?)\s*
            \z
        }x
    ) {
        my $field_name = $+{field_name};
        my $value = $+{value};
        my $comparator = $+{comparator};

        die "Unknown field in filter: '$field_name'\nUse --list-fields for list of known fields"
            unless $field_is_known{ $field_name };

        if($comparator eq '=') {
            return sub {
                return $_[0]->{$field_name} eq $value;
            };
        }
        elsif($comparator eq '!=') {
            return sub {
                return $_[0]->{$field_name} ne $value;
            };
        }
        elsif($comparator eq '~') {
            my $pattern = qr{$value};
            return sub {
                return $_[0]->{$field_name} =~ $pattern;
            };
        }
        elsif($comparator eq '!~') {
            my $pattern = qr{$value};
            return sub {
                return $_[0]->{$field_name} !~ $pattern;
            };
        }
        else {
            die "No implementation for filter comparator: '$comparator'";
        }
    }

    die "Unable to parse filter expression: $spec\n";
}


sub json_formatter {
    my($field_list) = @_;

    my $j = JSON()->new()->pretty(0);

    if($field_list) {
        my @fields = parse_field_list($field_list);
        return sub {
            my $rec = shift;
            my $fields_rec = {
                map { $_ => $rec->{$_} } @fields
            };
            return $j->encode($fields_rec);
        }
    }
    else {
        return sub {
            my $rec = shift;
            return $j->encode($rec);
        }
    }
}


sub make_formatter {
    my($template, $field_list) = @_;

    if(!$template) {
        if(!$field_list) {
            return;
        }
        $template = join ' ', map { "\${$_}" } parse_field_list($field_list);
    }

    my @out;
    while(
        $template =~ m{
            \G
            (?:
                \$\{(?<var>\w+)\}
                |\\(?<dollar>\$)
                |\\(?<backslash>\\)
                |(?<string>[^\$\\]+)
            )
        }xg
    ) {
        if($+{var}) {
            die "Unknown field: '$+{var}'\nUse --list-fields for list of known fields\n"
                unless $field_is_known{ $+{var} };
            push @out, [ $+{var} ];
        }
        elsif($+{dollar}) {
            push @out, '$';
        }
        elsif($+{backslash}) {
            push @out, '\\';
        }
        elsif($+{string}) {
            push @out, $+{string};
        }
    }

    return unless @out;

    return sub {
        my $rec = shift;
        return join '', map { ref($_) ? $rec->{$_->[0]} : $_ } @out;
    };
}


sub parse_field_list {
    my($field_list) = @_;

    my @names = ($field_list =~ m{(\w+)}g);
    foreach my $name (@names) {
        die "Unknown field: '$name'\nUse --fields for list of known fields\n"
            unless $field_is_known{$name};
    }
    return @names;
}


sub log_paths {
    if(-p STDIN) {
        return "-";
    }
    elsif(@_) {
        return map { abs_log_path($_) } @_;
    }
    else {
        if(my $files = $settings{log_files}) {
            if(ref($files) ne 'ARRAY') {
                die qq{Expected "log_files" in $conf_file to contain a JSON array [ ... ]\n};
            }
            return map { abs_log_path($_) } @$files;
        }
        return abs_log_path('/homeserver.log');
    }
}


sub abs_log_path {
    my($path) = @_;
    my ($volume, $directories, $file) = splitpath( $path );
    if($directories) {
        return $path;
    }
    else {
        return catfile(log_dir(), $path)
    }
}


sub log_dir {
    my($source, $path) = $settings{log_dir}
        ? ("configured", $settings{log_dir})
        : ("default", "/var/log/matrix-synapse");

    return $path if -d $path;

    if(-e $path) {
        die "The $source log directory '$path' exists but is not a directory\n";
    }
    else {
        die "The $source log directory '$path' does not exist\n";
    }
}


sub analyse_logs {
    my %args = @_;
    my $regex         = $args{regex};
    my $filter        = $args{filter};
    my $formatter     = $args{formatter};
    my $tally_output  = $args{tally_output};
    my $logs_files    = $args{log_files};

    my $buffer = MessageBuffer->new();
    my %tally;

    for my $path (@$logs_files) {
        my($log_file) = $path =~ m{([^/]+)$};
        my $fh;
        if($path eq '-') {
            $fh = \*STDIN;
        }
        else {
            open $fh, '<', $path;
        }
        LINE: while(my $line = <$fh>) {
            if($regex and $line !~ $regex) {
                next;
            }
            my %rec;
            chomp($line);
            if(my($prefix, $rest) = $line =~ m{\A(\S+):([0-9]{4}-[0-9]{2}-[0-9]{2} .*)\z}) {
                $path = $prefix;
                ($log_file) = $path =~ m{([^/]+)$};
                $line = $rest;
            }
            if($line =~ $request_line) {
                %rec = %+;
                $rec{log_path} = $path;
                $rec{log_file} = $log_file;
                $rec{ts_time} = $rec{ts_time} . '.' . delete($rec{ts_ms});
                $rec{timestamp} = $rec{ts_date} . 'T' . $rec{ts_time};
                $rec{req_query} //= '';
                if(
                    ($rec{user} // '') =~ m{
                        \A
                        @(?<user_local>[^:]+)
                        :(?<user_domain>.*)
                        \z
                    }xn
                ) {
                    $rec{user_local} = $+{user_local};
                    $rec{user_domain} = $+{user_domain};
                }
                else {
                    $rec{user_local} = '';
                    $rec{user_domain} = '';
                }
                if($filter and not $filter->(\%rec)) {
                    next LINE;
                }
                $rec{extra_lines} = $buffer->retrieve($rec{request_id}) // '';
                my $sep = $rec{extra_lines} ? "\n" : '';
                my $output = $formatter
                    ? $formatter->(\%rec)
                    : "$rec{extra_lines}$sep$line";
                if($tally_output) {
                    $tally{$output}++;
                }
                else {
                    say $output;
                }
            }
            elsif($line =~ $non_request_line) {
                %rec = %+;
                $rec{log_path} = $path;
                $rec{log_file} = $log_file;
                $rec{ts_time} = $rec{ts_time} . '.' . delete($rec{ts_ms});
                $rec{timestamp} = $rec{ts_date} . 'T' . $rec{ts_time};
                $rec{full_line} = $line;
                $buffer->store(\%rec);
            }
        }
    }

    if($tally_output) {
        my $max = 0;
        foreach my $i (values %tally) {
            $max = $i if $i > $max;
        }
        my $digits = length("$max") + 1;
        my @keys = sort { $tally{$a} <=> $tally{$b} } keys %tally;
        foreach my $key (@keys) {
            printf("%*u  %s\n", $digits, $tally{$key}, $key);
        }
    }
}


package MessageBuffer;

# If processing a request generates multiple log lines (typically INFO/WARN
# messages before the final response is logged and returned), they will be
# tied together by having the same request_id value.  This object is responsible
# for keeping track of the "non-request" lines until the final request line
# is seen.  It also discards "expired" lines - ones for which we never saw a
# matching request line in the 10 minutes after they were received.

sub new {
    my $class = shift;

    my $self = bless {
        @_,
        by_id => {},
        lru   => []
    }, $class;

    return $self;
}


sub store {
    my($self, $rec) = @_;

    my $request_id = $rec->{request_id};
    my $now = $self->time_value($rec->{timestamp}) or return;
    my $expiry = $now + $buffer_expiry;
    my $log_line = "    $rec->{full_line}";

    my($buf);
    if($buf = $self->{by_id}->{$request_id}) {
        my $lru = $self->{lru};
        @$lru = grep { $_ ne $request_id } @$lru;
    }
    else {
        $buf = $self->{by_id}->{$request_id} = {
            request_id  => $request_id,
            log_lines   => [],
        };
    }

    push @{ $buf->{log_lines} }, $log_line;
    $buf->{expiry} = $expiry;

    $self->_expire_cache($now);
    push @{ $self->{lru} }, $request_id;
}


sub retrieve {
    my($self, $request_id) = @_;

    my $buf = delete($self->{by_id}->{$request_id}) or return;
    my $lru = $self->{lru};
    @$lru = grep { $_ ne $request_id } @$lru;
    return join("\n", @{ $buf->{log_lines} });
}


sub time_value {
    my($self, $timestamp) = @_;

    if($timestamp =~ m{\A(\d\d\d\d)-(\d\d)-(\d\d)T(\d\d):(\d\d):(\d\d)}) {
        return POSIX::mktime($6, $5, $4, $3, $2 - 1, $1 - 1900);
    }
    return;
}


sub _expire_cache {
    my($self, $now) = @_;

    my $by_id = $self->{by_id};
    my $lru   = $self->{lru};
    while(@$lru) {
        my $request_id = $lru->[0];
        if(my $buf = $by_id->{$request_id}) {
            if($buf->{expiry} <= $now) {
                delete $by_id->{$request_id};
                shift @$lru;
                next;
            }
        }
        else {
            shift(@$lru);
            next;
        }
        return;
    }
}


__END__

=head1 NAME

synapse-log-analyzer - examine Synapse logs using filters and output formats

=head1 SYNOPSIS

  synapse-log-analyzer [options] [<files>]

  Options:

    --output <string>   a string for formatting each output line
    --fields <string>   a list of fields to include in the output
    --json              output records as JSON
    --filter <string>   an expression for selecting lines to output
    --bundle <name>     include a named "bundle" of options from config file
    --list-fields       list all known fields
    --regex <pattern>   a Perl regex used to "pre-filter" lines
    --tally             report number of occurrences of each output line
    --help              detailed help message

=head1 DESCRIPTION

A tool for examining Synapse log files with options to filter which lines
to include and to format the output.

=head1 OPTIONS

=over 4

=item B<< --bundle <name> >> (alias: B<-b>)

Include a named collection of option settings from the config file.

=item B<< --fields <string> >>

Specify which fields you want included in the output, as either a comma or space
delimited string.  Example:

  --fields 'timestamp,user,resp_code,req_method,req_path'

The special field C<extra_lines> will potentially contain newline characters.
This field contains any messages that were logged with the same C<request_id>
while the request was being processed and before the response was sent.

=item B<< --filter <filter-string> >> (alias: B<-f>)

A filter expression describing which lines should be included in the output.
Examples:

  --filter 'resp_code = 401'
  --filter 'user = @john:example.com'
  --filter 'user != None'

You can use this option multiple times to define multiple filters, which will be
combined using a logical "and" (i.e.: output will reflect lines that matched all
filters).

=item B<< --help >> (alias: B<-?>)

Display this documentation.

=item B<< --json >>

Output each filtered log line re-formatted as a JSON object.  The objects won't
have a trailing comma and there will be no array wrapper, so the output as a
whole won't constitute a valid JSON document. However you'll still be able to
feed it into C<jq> etc.

=item B<< --list-fields >>

List all known fields.

=item B<< --output <format-string> >> (alias: B<-o>)

A string specifying the output for each output line.  The format string can
contain literal text and named field values in the form: C<${field_name}>.
For example:

  --output 'user="${user}" status_code="${resp_status}"'

=item B<< --regex <pattern> >>

A user-supplied Perl regular expression which is used to pre-filter the log
lines.  This can be used to speed processing by skipping the step of parsing
every field for lines which aren't considered interesting.

=item B<< --tally >>

Instead of outputting each line, keep a count of how many times each one occurs
and output a summary at the end.

=back

=head1 CONFIG FILE

This script will read default settings from the F<~/.synapse-log-analyzer.json>
file in the user's home directory.

Here's an example config file:

{
    "log_dir": "/var/log/matrix-synapse",
    "log_files": [
        "homeserver.log",
        "generic1.log",
        "generic2.log",
        "generic3.log"
    ],
    "bundles": {
        "permission_denied": [
            "--filter", "resp_code = 403",
            "--filter", "req_path !~ ^/_matrix/media"
        ],
        "json_brief": [
            "--json",
            "--fields", "user_local,resp_code,req_method,req_path"
        ]
    }
}


=head1 LINKS

The git repository for this script is at:
https://github.com/grantm/synapse-log-analyzer

=head1 COPYRIGHT

This script was written by Grant McLean <grantm@cpan.org>.  You can
redistribute it and/or modify it under the terms of the Apache License
version 2.0 or later.

=cut



